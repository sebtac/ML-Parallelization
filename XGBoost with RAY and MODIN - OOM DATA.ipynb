{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65475324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASED ON: https://medium.com/intel-analytics-software/distributed-xgboost-with-modin-on-ray-fc17edef7720\n",
    "\n",
    "DATASET:\n",
    "    - HIGGS.csv\n",
    "    - 8GB\n",
    "    \n",
    "    \n",
    "PLATFORM:\n",
    "    - M1 - Both MODIN and RAY/PANDAS worked; SharedRayDMatrix with (parquet) NOT TESTED\n",
    "    - AWS SM ml.m3.medium - NONE worked - OOM Errors\n",
    "        - NEXT STEP: find minium instance that allows execution\n",
    "    \n",
    "FINDINGS:\n",
    "    - MODIN with MODIN.DISTRIBUTED datasets offers by far the best performance (measued in miliseconds vs. seconds)\n",
    "    - Both MODIN and RAY/PANDAS do not speed up with increase in \"num_actors\" parameter\n",
    "    - RAY with PANDAS data does take some advantege of multiple \"cpus_per_actor\" parameter when measured with Wall Time\n",
    "    - SharedRayDMatrix with (parquet) dies with OOM Error on 4GB Mem Instance - due to the load of the whole input data into memoryby XGBoost\n",
    "        - NEXT STEP - test with PIPE Model on AWS Implementation - See AWS notebook\n",
    "        - NEXT STEP - Test with Modin and Parquet ... in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dad3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# TEST 1 - GET DATA\n",
    "# - XGBOOST on HIGGS dataset\n",
    "# - Pure Pandas (CSV) vs. Modin (CSV) vs. SharedRayDMatrix with (parquet)\n",
    "\n",
    "engine = 1 # 0 Pandas, 1 Modin, 2 Sharded RayDMatrix\n",
    "\n",
    "if engine == 0:\n",
    "    print(\"engine: Pandas\")\n",
    "    import pandas as pd\n",
    "    from xgboost_ray import RayDMatrix, RayParams, train\n",
    "    df = pd.read_csv(\"HIGGS.csv\")\n",
    "    dmatrix = RayDMatrix(df.iloc[:,:-1], df.iloc[:,-1])\n",
    "elif engine == 1:\n",
    "    print(\"engine: Modin\")\n",
    "    import modin.pandas as pd\n",
    "    import modin.experimental.xgboost as xgb\n",
    "    import ray\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    print(1)\n",
    "    df = pd.read_csv(\"HIGGS.csv\")\n",
    "    print(2)\n",
    "    dmatrix = xgb.DMatrix(df.iloc[:,:-1], df.iloc[:,-1])\n",
    "    print(3)\n",
    "elif engine == 2:\n",
    "    print(\"engine: SharedRayDMatrix with (parquet)\")    \n",
    "    import glob\n",
    "    from xgboost_ray import RayDMatrix, RayFileType, RayParams, train\n",
    "\n",
    "    # list of files to pass to estimator\n",
    "    path = list(sorted(glob.glob(\"HIGGS_DATA/*.parquet\")))\n",
    "    print(\"PATH\", path)\n",
    "\n",
    "    # OPTIONAL: Specify colums in .parqut files to load to the estimator`- in this test they were removed\n",
    "    \"\"\"\n",
    "    columns = [\"passenger_count\",\n",
    "        \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "        \"dropoff_longitude\", \"dropoff_latitude\",\n",
    "        \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\",\n",
    "        \"tolls_amount\", \"total_amount\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    dmatrix = RayDMatrix(path,\n",
    "                         label = \"28\", #\"passenger_count\",  # Will select this column as the label\n",
    "                         #columns=columns,\n",
    "                         # ignore=[\"total_amount\"],  # Optional list of columns to ignore\n",
    "                         filetype=RayFileType.PARQUET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4bb4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# TEST 1 - RUN MODEL\n",
    "\n",
    "if engine == 0: \n",
    "    model = train({}, dmatrix, ray_params=RayParams(num_actors=1, cpus_per_actor=10))\n",
    "elif engine == 1:\n",
    "    model = xgb.train({}, dmatrix, num_actors=1)\n",
    "elif engine == 2:\n",
    "    model = train({}, dmatrix, ray_params=RayParams(num_actors=1, cpus_per_actor=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe91ca7-ac99-4b46-8b3b-98d3f5832095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH PANDAS - M1\n",
    "num_actors=10, cpus_per_actor=1\n",
    "in 190.63 seconds (106.33 pure XGBoost training time).\n",
    "CPU times: user 5.96 s, sys: 2min 39s, total: 2min 45s\n",
    "Wall time: 3min 10s\n",
    "\n",
    "num_actors=1, cpus_per_actor=1\n",
    "20.36 seconds (9.84 pure XGBoost training time).\n",
    "CPU times: user 411 ms, sys: 16.2 s, total: 16.6 s\n",
    "Wall time: 20.4 s\n",
    "\n",
    "num_actors=1, cpus_per_actor=10    \n",
    "in 15.64 seconds (9.45 pure XGBoost training time).\n",
    "CPU times: user 467 ms, sys: 15.5 s, total: 16 s\n",
    "Wall time: 15.9 s\n",
    "    \n",
    "# WITH MODIN - M1\n",
    "num_actors=10\n",
    "2nd RUN!!! (without relaod of ray and modin)\n",
    "CPU times: user 63.1 ms, sys: 42 ms, total: 105 ms\n",
    "Wall time: 8.69 s\n",
    "    \n",
    "1st RUN - CPU times around 120ms!!!\n",
    "    \n",
    "num_actors=1    \n",
    "1st RUN\n",
    "CPU times: user 149 ms, sys: 43.3 ms, total: 192 ms\n",
    "Wall time: 16.8 s\n",
    "\n",
    "2nd RUN!!! (without relaod of ray and modin)    \n",
    "CPU times: user 32 ms, sys: 25.1 ms, total: 57.1 ms\n",
    "Wall time: 10.6 s    \n",
    "    \n",
    "    \n",
    "num_actors=10 with ray.init()\n",
    "1st RUN\n",
    "CPU times: user 122 ms, sys: 51.4 ms, total: 173 ms\n",
    "Wall time: 9.46 s\n",
    "    \n",
    "2nd RUN!!!! (without relaod of ray and modin)\n",
    "CPU times: user 65.3 ms, sys: 38.5 ms, total: 104 ms\n",
    "Wall time: 8.22 s\n",
    "\n",
    "# SharedRayDMatrix with (parquet) - AWS ml.m3.medium\n",
    "\n",
    "- OOM Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a38dc2-6201-4d0e-8ce8-adb580b7a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix OOM with Modin -- Partially Successfull!\n",
    "\n",
    "BASED ON: https://modin.readthedocs.io/en/stable/getting_started/why_modin/out_of_core.html\n",
    "\n",
    "- Presumably Modin should allow work with datasets that do not fit into memory.\n",
    "- While it delivered better performance than pure pandas, we still run into OOM errors\n",
    "- USE ray.init(_plasma_directory=\"/tmp\") - A SETTING TO DISABLE OUT-OF-CORE RAY, which let's MODIN handle larger datasets but still results with OOM\n",
    "- POSSIBLY execution failed as the ml.m3.medium istance has only 4GB of RAM thus OOM errors might be caused not by the size of data itslef but\n",
    "- due to internal workings of the algorithm or system level issues\n",
    "\n",
    "- NEXT STEP: test on bigger instance with more data\n",
    "- NEXT STEP: Implement Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435987b4-8267-4d4a-b195-14358cb3c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT SIZE CHECK\n",
    "2**15 * 2**8, 2**15 * 2**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e852ae-30a9-4440-bcff-8bca079fef22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WITH PURE PANDAS\n",
    "import pandas\n",
    "import numpy as np\n",
    "df = pandas.concat([pandas.DataFrame(np.random.randint(0, 100, size=(2**15, 2**8))) for _ in range(20)]) # Memory Error!\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3bf144-f301-462d-8213-91fff6e9d7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WITH PURE PANDAS - ITERATIVE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(50):    \n",
    "    df = pd.concat([df, pd.DataFrame(np.random.randint(0, 100, size=(2**15, 2**8)))]) # BREAKS around 20-25 iteration!!!\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0819a-27c6-45ae-a084-dd09787611c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WITH MODIN\n",
    "\n",
    "# REQUIRES KERNEL RESTARTS or WORKOUT PROPER ray.actor KILLING\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "ray.init(_plasma_directory=\"/tmp\") # SETTING TO DISABLE OUT-OF-CORE RAY !?!??! - MAKES IT ALL WORK\n",
    "\n",
    "#df = pd.concat([pd.DataFrame(np.random.randint(0, 100, size=(2**15, 2**8))) for _ in range(25)]) # Working!!!\n",
    "df = pd.concat([pd.DataFrame(np.random.randint(0, 100, size=(2**15, 2**8))) for _ in range(50)]) # Working with PLASMA!!!\n",
    "#df = pd.concat([pd.DataFrame(np.random.randint(0, 100, size=(2**15, 2**8))) for _ in range(100)]) # OOM ERROR!!!\n",
    "df.info()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c1007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc3248-4c96-4335-93c1-5af6d4a9149c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init()\n",
    "\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(50):    \n",
    "    df = pd.concat([df, pd.DataFrame(np.random.randint(0, 100, size=(2**15, 2**8)))]) # Working!!!\n",
    "    df.info()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL MINI TESTS OF PANDAS vs. MODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"HIGGS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 with 10 CORES\n",
    "\n",
    "with PANDAS\n",
    "CPU times: user 35.4 s, sys: 3.48 s, total: 38.9 s\n",
    "Wall time: 40.1 s\n",
    "    \n",
    "with MODIN\n",
    "CPU times: user 3.44 s, sys: 2.02 s, total: 5.45 s\n",
    "Wall time: 23.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca776a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 with 10 CORES\n",
    "\n",
    "with PANDAS\n",
    "CPU times: user 7.55 s, sys: 1.33 s, total: 8.87 s\n",
    "Wall time: 9.33 s\n",
    "    \n",
    "with MODIN\n",
    "CPU times: user 102 ms, sys: 63.5 ms, total: 165 ms\n",
    "Wall time: 11.6 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed04912",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.groupby(df.columns[0]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e2b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 with 10 CORES\n",
    "\n",
    "with PANDAS\n",
    "CPU times: user 1.11 s, sys: 101 ms, total: 1.21 s\n",
    "Wall time: 1.21 s\n",
    "    \n",
    "with MODIN\n",
    "CPU times: user 28.3 ms, sys: 13.3 ms, total: 41.6 ms\n",
    "Wall time: 409 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 with 10 CORES\n",
    "\n",
    "with PANDAS\n",
    "CPU times: user 415 ms, sys: 4.53 ms, total: 420 ms\n",
    "Wall time: 417 ms\n",
    "    \n",
    "with MODIN\n",
    "CPU times: user 16 ms, sys: 3.13 ms, total: 19.1 ms\n",
    "Wall time: 18.6 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0e961-2a69-414e-b44c-c1c06340361f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "###### HELPER FUCNTIONS, ENV SETUP ######\n",
    "#########################################\n",
    "\n",
    "!pip install -U ray xgboost_ray modin pyarrow\n",
    "# modin[ray] -- Results in BrokenPipe Error and without specyfying ray it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e88d8-969c-4c3e-a118-bc31c8df02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET HIGGS DATASET -- CSV\n",
    "\n",
    "# AWS Python SDK\n",
    "import boto3\n",
    "\n",
    "# When running on SageMaker, need execution role\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "# Declare bucket name, remote file, and destination\n",
    "my_bucket = 'data-distributions'\n",
    "orig_file = 'HIGGS/HIGGS.csv.zip'\n",
    "dest_file = 'HIGGS.csv.zip'\n",
    "\n",
    "# Connect to S3 bucket and download file\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(my_bucket).download_file(orig_file, dest_file)\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"HIGGS.csv.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1aae3-2344-46a2-849c-a4d379fa4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE PARQUET FILES:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "col_str = [str(i) for i in df.columns]\n",
    "df.columns = col_str\n",
    "\n",
    "list_df = np.array_split(df, 40)\n",
    "\n",
    "for n, i in enumerate(list_df):\n",
    "    print(n, i.shape, type(i))\n",
    "    i.to_parquet('HIGHGS_'+str(n)+'.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939089d-5f11-4853-be86-0941ebed1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLY PARQUET FILES\n",
    "\n",
    "import shutil\n",
    "\n",
    "src = \"PARQUET/abalone_train_33.parquet\"\n",
    "\n",
    "for i in range(256):\n",
    "    file_id = str(97 + i + 1)\n",
    "    dst = \"PARQUET/abalone_train_\"+file_id+\".parquet\"\n",
    "    shutil.copy2(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd95892-4659-40cf-89e5-81c89c3add5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARTIONED MODIN DATASET - ATTEMPT - TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modin.pandas as pd\n",
    "#import ray\n",
    "\n",
    "# TO CONNECT WITH EXISTING CLUSTER\n",
    "#ray.init(address=\"auto\")\n",
    "#ray.init(address=\"127.0.0.1:PORT\")\n",
    "\n",
    "df = pd.read_csv(\"HIGGS.csv\")\n",
    "\n",
    "model.best_iteration, model.attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "from modin.distributed.dataframe.pandas import unwrap_partitions, from_partitions\n",
    "import numpy as np\n",
    "data = np.random.randint(0, 100, size=(2 ** 10, 2 ** 8))\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "#partitions = unwrap_partitions(df, axis=0, get_ip=True)\n",
    "partitions = unwrap_partitions(df, axis=0)\n",
    "print(partitions) #, type(partitions), len(partitions), partitions[0], dir(partitions[0]))\n",
    "new_df = from_partitions(partitions, axis=0)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81711b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dmatrix = xgb.DMatrix(partitions.iloc[:,:-1], partitions.iloc[:,-1])\n",
    "model = xgb.train({}, dmatrix, num_actors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447ad48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
